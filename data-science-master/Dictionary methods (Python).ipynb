{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary methods\n",
    "\n",
    "## Dataset for the exercise\n",
    "\n",
    "* [New York Times Comments](https://www.kaggle.com/aashita/nyt-comments/data), set of reders' comments for articles published in the New York Times\n",
    "\n",
    "## Overarching research question\n",
    "\n",
    "The comments allow a perspective to study what kind of concerns people raise when commenting to online articles.\n",
    "Study what seem to be the target of the commenting: New York Times staff or journalistic guidelines (suggesting that comments serveas a tool for journalists to interact with their audiences _or_ other audience members)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = \"New York Times,NYT\"\n",
    "keywords = keywords.lower()\n",
    "keywords = keywords.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/nyt-comments/'\n",
    "files = os.listdir( path ) ## see all files in directory\n",
    "files = filter( lambda file_name: file_name.startswith(\"Comments\"), files ) ## choose only data files\n",
    "files = map( lambda file_name: path + file_name, files ) ## add path to file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "comments = 0\n",
    "\n",
    "for file in files:\n",
    "    for entry in csv.DictReader( open( file ) ):\n",
    "        \n",
    "        comments += 1\n",
    "        \n",
    "        comment = entry['commentBody']\n",
    "        \n",
    "        ## work through several different keywords in the analysis\n",
    "        for keyword in keywords: \n",
    "            if keyword in comment.lower():\n",
    "                counter += 1\n",
    "                break\n",
    "\n",
    "print( counter, \"comments mention any of these:\", ','.join(keywords) )\n",
    "print( \"There are in total\", comments )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Identify other potential keywords for this phenomena and add those keywords in the list.\n",
    "* Are there any cases where this approach might break? modify the code to mitigate them when possible\n",
    "* The data has `createDate` variable as well which identifies when the comment was created. Based on this, try to look for some temporal trends in comment counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language analysis\n",
    "\n",
    "In many languages, different words can have different forms. For example, 'I have an apple' and 'I have several apples' convey almost the same information, similarly 'She had an apple' and 'She has an apple' are almost identical. In Finnish language, such examples are much more extensive thanks to the many suffixes words may have several forms.\n",
    "\n",
    "![Joke about conjugation](https://dailymagyar.files.wordpress.com/2015/10/kutya_meme_ps_2.png)\n",
    "\n",
    "This might make analysis difficult! Therefore often the language is **stemmed** or **lemmatized** into its basic form. Furthermore, tools such as [Natural Language Toolkit](https://www.nltk.org/) allow parsing text to identify proper nouns, identify named entities or determine if a word is adjective, noun etc.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Use same dataset.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Replicate the previous exercise using proper stemmatization. If results change, how and why?\n",
    "\n",
    "How would you use this to create a word-document matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'This is a longer example! Many words are included here, and we shall all words.'\n",
    "stemmed = ''\n",
    "\n",
    "for word in nltk.word_tokenize( message ):\n",
    "    stemmed += stemmer.stem( word ) + ' '\n",
    "    \n",
    "print( stemmed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
