---
title: An R Markdown document converted from "data-science-master/K-means and clustering
  (R).ipynb"
output: html_document
---

# K-means

## Data

Use the [World Value Survey](http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp) datafiles and corresponding questionaire and codebook files to understand what is in the data.

## Overarching research question

What kind of responder groups can emerge from survey responders and do they correspond to nationalities?
* Choose some relevant measurements
* Run analysis
* Interprent

## Tools

[Kmeans](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/kmeans) is inbuild to R.

```{r}
## create new data matrix for k-means analysis

selected_keys <- c('V4', 'V5', 'V6', 'V7', 'V8', 'V9')

full_data <- read.csv('data/wvs.csv')

data <- full_data[,selected_keys ]

print( nrow( data ) )
```

```{r}
kmeans_results <- kmeans( data, centers = 10 )

clustering_results <- kmeans_results$cluster

## number of responders per cluster

table( clustering_results )
```

Now we have created a **ten cluster** approach.
How do we know if it is any good?

What would be different if we create a **five cluster** model instead?

Let's examine the mean values per each of the identified cluster.

```{r}
aggregate(data, by=list(clustering_results), FUN=mean)
```

## Task

* Run the above code and explain to yourself what is done.
* Response values -1, -2 and -3 relate to missing data (people answering I don't know etc.). Clean these values away from the dataset and redo your analysis.
* Choose suitable variables using the codebook and your understanding and intuition.
* Modify the number of clusters and examine how results change.

## Looking inside K-means

Often we prefer to use some data-driven approaches to identify the best number of clusters. One way to achieve this is to use the [elbow_ method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)), where we visually inspect the best number of topics. Other tools exists as well, such as the [Silhouette method](https://en.wikipedia.org/wiki/Silhouette_(clustering)). Elbow is simple, but not always that clear and other methods are preferred. However, it is easy to understand.

The Elbow-method measures the distance clusters' items have to the centroid (sum of squared errors, sse). It can range from 0 (all items in the clusters are at the same point as its centroid) to positive infinity (nodes are all over the place). When numer or clusters (k) is increased, it decreases SSE; but this is a balancing act: how do you balance between more clusters and additional complexity and most explainability?

```{r}
sse <- c()

for(k in 2:10) {
    result <- kmeans( data, centers = k )
    sse <- c( sse, result$tot.withinss ) ## this is slow in R, but when doing a list of ten items it is OK.
}
```

```{r}
plot( 2:10, sse, type="b")
```

## Tasks

* Draw three different k-means clusterings with centroids and related values and organize them by their SSE.
* Use the elbow method to optimize your model.
* What similarities can you find between k-means and factor analysis?
* How does k-means differ from factor analysis? 

